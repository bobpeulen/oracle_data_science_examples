{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b98b8a",
   "metadata": {},
   "source": [
    "# **Tabular GAN**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15685d84",
   "metadata": {},
   "source": [
    "## **1. Conda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18104a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fdf_conda used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e2e6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Establish connection between notebook session and your newly created bucket.\n",
    "!odsc conda init -b conda_environment_yolov5 -n frqap2zhtzbe -a resource_principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0703d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Publish the 'object_detection_apex_conda' to the bucket. Make sure the bucket has no other custom conda environment, this will partly be overwritten\n",
    "#!odsc conda publish -s fdf_conda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee13071",
   "metadata": {},
   "source": [
    "## **2. Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9197381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ads.model.framework.tensorflow_model import TensorFlowModel\n",
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "from ads.common.model_export_util import prepare_generic_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31433977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:ADS:As force_overwrite is set to True, all the existing files in the /home/datascience/model_artifacts will be removed\n",
      "WARNING:ADS:Taxonomy metadata was not extracted. To auto-populate taxonomy metadata the model must be provided. Pass the model as a parameter to .prepare_generic_model(model=model, usecase_type=UseCaseType.REGRESSION). Alternative way is using atifact.populate_metadata(model=model, usecase_type=UseCaseType.REGRESSION).\n"
     ]
    }
   ],
   "source": [
    "#path to artifacts and conda slug\n",
    "path_to_artifacts = '/home/datascience/model_artifacts'\n",
    "conda_env = 'oci://conda_environment_yolov5@frqap2zhtzbe/conda_environments/cpu/fdf_conda/1.0/fdf_conda'   #this refers to the published conda location (bucket name, namespace)\n",
    "\n",
    "#create default artifacts\n",
    "artifact = prepare_generic_model(path_to_artifacts, fn_artifact_files_included=False, force_overwrite=True, inference_conda_env=conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ff4d6",
   "metadata": {},
   "source": [
    "## **3. Change score.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bde5ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/datascience/model_artifacts/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"{path_to_artifacts}/score.py\"\n",
    "\n",
    "import ocifs\n",
    "import os\n",
    "from ocifs import OCIFileSystem\n",
    "import pandas as pd\n",
    "from sdv.demo import load_tabular_demo\n",
    "from sdv.tabular import CTGAN\n",
    "\n",
    "########################### ########################### ########################### ########################### \n",
    "########################### \n",
    "########################### Load a dummy model\n",
    "########################### \n",
    "########################### ########################### ########################### ########################### \n",
    "\n",
    "\n",
    "def load_model():\n",
    "    class DummyModel:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "    return DummyModel()\n",
    "\n",
    "\n",
    "#######################################################\n",
    "####################################################### predict\n",
    "#######################################################\n",
    "\n",
    "def predict(data, model=load_model()):\n",
    "    \n",
    "    prim_key = data[\"prim_key\"]\n",
    "    csv_name = data[\"csv_name\"]\n",
    "    number_new_rows = data[\"number_new_rows\"]\n",
    "    \n",
    "    #get the csv file from bucket\n",
    "    input_location = \"oci://West_BP@frqap2zhtzbe/\"\n",
    "    input_csv = pd.read_csv(input_location + csv_name)\n",
    "\n",
    "    #get max 200 rows to train on\n",
    "    data_short = input_csv.head(200)\n",
    "    \n",
    "    #load ctgan model\n",
    "    model = CTGAN(primary_key=prim_key)\n",
    "    \n",
    "    #fit model on short data\n",
    "    model.fit(data_short)\n",
    "    \n",
    "    #output file name\n",
    "    output_file_name = \"/home/datascience/synthetic_\" + csv_name\n",
    "    \n",
    "    #delete file\n",
    "\n",
    "    if os.path.exists(output_file_name):\n",
    "        os.remove(output_file_name)\n",
    "    else:\n",
    "        print(\"The file does not exist yet, but that's fine\")\n",
    "    \n",
    "    #c\n",
    "    \n",
    "    #create new synthetic rows\n",
    "    new_data = model.sample(num_rows = number_new_rows, output_file_path = output_file_name)  #defaults to ./ to save\n",
    "    \n",
    "            \n",
    "    fs = OCIFileSystem()\n",
    "    fs.invalidate_cache()\n",
    "    \n",
    "    new_csv_local_path = os.path.join(\"/home/datascience/\", output_file_name)\n",
    "    print(new_csv_local_path)\n",
    "       \n",
    "    with open(new_csv_local_path, 'rb') as f:\n",
    "        with fs.open(input_location + os.path.basename(new_csv_local_path), 'wb') as file_out:\n",
    "            file_out.write(f.read())\n",
    "            \n",
    "    done = print(\"Synthetic .csv file is available\")\n",
    "    \n",
    "    return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c210dd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/datascience/synthetic_Metro_Interstate_Traffic_Volume_Edit.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>date_time</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>298.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>a</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>278.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>Clear</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>b</td>\n",
       "      <td>2711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>271.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>c</td>\n",
       "      <td>2318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>274.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>d</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>280.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>Clear</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>e</td>\n",
       "      <td>2365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>None</td>\n",
       "      <td>288.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>dL</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>None</td>\n",
       "      <td>282.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>few clouds</td>\n",
       "      <td>dM</td>\n",
       "      <td>4623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>None</td>\n",
       "      <td>272.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>dN</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>None</td>\n",
       "      <td>296.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>dO</td>\n",
       "      <td>2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>None</td>\n",
       "      <td>272.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>dP</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
       "0      None  298.17      0.0      0.0           0         Rain   \n",
       "1      None  278.78      0.0      0.0          11        Clear   \n",
       "2      None  271.22      0.0      0.0           0       Clouds   \n",
       "3      None  274.68      0.0      0.0          85        Clear   \n",
       "4      None  280.88      0.0      0.0          24        Clear   \n",
       "..      ...     ...      ...      ...         ...          ...   \n",
       "245    None  288.29      0.0      0.0          70       Clouds   \n",
       "246    None  282.29      0.0      0.0          83       Clouds   \n",
       "247    None  272.86      0.0      0.0           0       Clouds   \n",
       "248    None  296.81      0.0      0.0          80       Clouds   \n",
       "249    None  272.26      0.0      0.0          40       Clouds   \n",
       "\n",
       "    weather_description date_time  traffic_volume  \n",
       "0      scattered clouds         a             651  \n",
       "1            few clouds         b            2711  \n",
       "2         broken clouds         c            2318  \n",
       "3          sky is clear         d             251  \n",
       "4      scattered clouds         e            2365  \n",
       "..                  ...       ...             ...  \n",
       "245    scattered clouds        dL             251  \n",
       "246          few clouds        dM            4623  \n",
       "247        sky is clear        dN             992  \n",
       "248     overcast clouds        dO            2671  \n",
       "249        sky is clear        dP             251  \n",
       "\n",
       "[250 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"prim_key\":\"date_time\", \"csv_name\":\"Metro_Interstate_Traffic_Volume_Edit.csv\", \"number_new_rows\":250}\n",
    "predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2d114",
   "metadata": {},
   "source": [
    "## **4. Store in model catalog**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "576f6471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_json_output.json', '.ipynb_checkpoints', 'runtime.yaml', 'score.py']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test key</th>\n",
       "      <th>Test name</th>\n",
       "      <th>Result</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runtime_env_path</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>runtime_env_python</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>runtime_path_exist</td>\n",
       "      <td>Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>runtime_version</td>\n",
       "      <td>Check that field MODEL_ARTIFACT_VERSION is set to 3.0</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>runtime_yaml</td>\n",
       "      <td>Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>score_load_model</td>\n",
       "      <td>Check that load_model() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>score_predict</td>\n",
       "      <td>Check that predict() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>score_predict_arg</td>\n",
       "      <td>Check that all other arguments in predict() are optional and have default values</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>score_predict_data</td>\n",
       "      <td>Check that the only required argument for predict() is named \"data\"</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>score_py</td>\n",
       "      <td>Check that the file \"score.py\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>score_syntax</td>\n",
       "      <td>Check for Python syntax errors</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test key  \\\n",
       "0     runtime_env_path   \n",
       "1   runtime_env_python   \n",
       "2   runtime_path_exist   \n",
       "3      runtime_version   \n",
       "4         runtime_yaml   \n",
       "5     score_load_model   \n",
       "6        score_predict   \n",
       "7    score_predict_arg   \n",
       "8   score_predict_data   \n",
       "9             score_py   \n",
       "10        score_syntax   \n",
       "\n",
       "                                                                                                Test name  \\\n",
       "0                                             Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set   \n",
       "1           Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher   \n",
       "2                             Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.   \n",
       "3                                                   Check that field MODEL_ARTIFACT_VERSION is set to 3.0   \n",
       "4   Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory   \n",
       "5                                                                      Check that load_model() is defined   \n",
       "6                                                                         Check that predict() is defined   \n",
       "7                        Check that all other arguments in predict() are optional and have default values   \n",
       "8                                     Check that the only required argument for predict() is named \"data\"   \n",
       "9       Check that the file \"score.py\" exists and is in the top level directory of the artifact directory   \n",
       "10                                                                         Check for Python syntax errors   \n",
       "\n",
       "    Result Message  \n",
       "0   Passed          \n",
       "1   Passed          \n",
       "2   Passed          \n",
       "3   Passed          \n",
       "4   Passed          \n",
       "5   Passed          \n",
       "6   Passed          \n",
       "7   Passed          \n",
       "8   Passed          \n",
       "9   Passed          \n",
       "10  Passed          "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all should be passed\n",
    "artifact.introspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bf9994b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact:/tmp/saved_model_e0755524-de4b-4a59-b11e-afa6add3daf8.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ocid1.datasciencemodel.oc1.eu-frankfurt-1.amaaaaaangencdyamolhca4nilqxjnz6bgq6xrjjau647lhtfwhm6npgkstq'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model artifact to the model catalog. \n",
    "catalog_entry = artifact.save(display_name='synthetic_gan_v3', description='synthetic_gan_v3', timeout=600)\n",
    "\n",
    "catalog_entry.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354e8ee",
   "metadata": {},
   "source": [
    "## **Deploy in UI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e50d434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf8ec7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://modeldeployment.eu-frankfurt-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.eu-frankfurt-1.amaaaaaangencdyackrqrerar5yzqfi4rzcdtzp7xwhoiuc3rd6an22lwiya/predict\n"
     ]
    }
   ],
   "source": [
    "uri = f\"https://modeldeployment.eu-frankfurt-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.eu-frankfurt-1.amaaaaaangencdyackrqrerar5yzqfi4rzcdtzp7xwhoiuc3rd6an22lwiya/predict\"\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d70b179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "CPU times: user 87.3 ms, sys: 5.64 ms, total: 92.9 ms\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auth = oci.auth.signers.get_resource_principals_signer()\n",
    "\n",
    "data = {\"prim_key\":\"date_time\", \"csv_name\":\"Metro_Interstate_Traffic_Volume_Edit.csv\", \"number_new_rows\":250}\n",
    "\n",
    "response = requests.post(uri, json=data, auth=auth)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47a04e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.loads(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688a786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975a684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fdf_conda]",
   "language": "python",
   "name": "conda-env-fdf_conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
