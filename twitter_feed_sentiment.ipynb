{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c64b71",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3bf818",
   "metadata": {},
   "source": [
    "# **Tweets, Users, Sentiment, and Key Phrases**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a7540",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c335c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_input = \"2023-05-21\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfaaa8d",
   "metadata": {},
   "source": [
    "# **1. Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5337b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports are done\n"
     ]
    }
   ],
   "source": [
    "import ads\n",
    "import os\n",
    "import sqlalchemy \n",
    "import oci\n",
    "import tweepy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pandas import json_normalize \n",
    "import cx_Oracle\n",
    "from ads.database import connection \n",
    "from ads.database.connection import Connector\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.request import urlopen\n",
    "import configparser\n",
    "import re\n",
    "import random\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "from tempfile import NamedTemporaryFile\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "from cleantext import clean\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "print(\"Imports are done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30428bce",
   "metadata": {},
   "source": [
    "# **2. Authenticate Against OCI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4d1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oci.config import from_file\n",
    "config = oci.config.from_file(file_location='~/.oci/config', profile_name='DEFAULT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee18452",
   "metadata": {},
   "source": [
    "# **4. Get latest Tweets from Twitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b63a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Riders and team only. Not staff\n",
    "list_of_twitter = [\"@soudalquickstep\", \"#soudalquickstep\", \"(from:soudalquickstep)\",\n",
    "#                   \"@EthanVernon22\", \n",
    "                     \"@cernyjosef\",\n",
    "#                    \"@alafpolak1\",\n",
    "#                     \"@k_asgreen\",\n",
    "#                   \"@AndreaBagioli\",\n",
    "                    \"@ballero_94\",\n",
    "                   \"@cattamat\",\n",
    "# # #                   \"@remicav\",\n",
    "#                    \"@Tim_Declercq\",\n",
    "# # #                   \"@3sdevenyns\",\n",
    "                    \"@EvenepoelRemco\",\n",
    "                     \"@HirtJan\",\n",
    "#                     \"@FabioJakobsen\",                \n",
    "# #                   \"@JamesKnoxx\",\n",
    "# #                   \"@yveslampaert\",\n",
    "#                    \"@masnada_fausto\",\n",
    "# #                   \"@MerlierTim\",\n",
    "#                   \"@MichaelMorkov\",\n",
    "#                   \"@pedersencasp\",\n",
    "#                   \"@mauro_schmid\",\n",
    "#                   \"@flosenech\",\n",
    "                   \"@Pieter_Serry\",\n",
    "#                   \"@SteimleJannik\",\n",
    "#                   \"@sv_rtin\",\n",
    "#                   \"@bert_bvl\",\n",
    "#                   \"@StanVanTricht\",\n",
    "                    \"@IlanWilder\",\n",
    "#                   \"@MVansevenant99\",\n",
    "#                   \"@EthanVernon22\",\n",
    "                  \"@LouisVervaeke\"\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09efeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T00:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T00:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T00:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T00:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T00:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T00:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T00:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T00:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T00:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T00:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T00:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T00:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T00:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T00:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T01:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T01:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T01:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T01:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T01:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T01:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T01:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T01:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T01:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T01:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T01:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T01:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T01:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T01:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T02:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T02:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T02:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T02:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T02:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T02:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T02:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T02:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T02:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T02:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T02:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T02:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T02:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T02:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T03:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T03:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T03:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T03:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T03:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T03:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T03:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T03:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T03:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T03:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T03:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T03:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T03:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T03:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T04:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T04:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T04:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T04:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T04:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T04:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T04:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T04:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T04:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T04:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T04:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T04:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T04:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T04:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T05:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T05:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T05:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T05:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T05:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T05:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T05:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T05:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T05:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T05:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T05:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T05:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T05:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T05:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T06:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T06:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T06:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T06:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T06:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T06:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T06:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T06:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T06:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T06:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T06:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T06:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T06:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T06:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T07:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T07:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T07:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T07:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T07:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T07:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T07:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T07:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T07:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T07:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T07:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T07:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T07:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T07:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T08:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 20 in time block 2023-05-21T08:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T08:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T08:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T08:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T08:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T08:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T08:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 19 in time block 2023-05-21T08:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 57 in time block 2023-05-21T08:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T08:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T08:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T08:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T08:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T09:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T09:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 56 in time block 2023-05-21T09:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T09:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T09:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T09:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T09:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T09:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T09:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 53 in time block 2023-05-21T09:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T09:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T09:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T09:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T09:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T10:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T10:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 51 in time block 2023-05-21T10:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T10:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T10:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T10:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T10:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T10:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T10:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 51 in time block 2023-05-21T10:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T10:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T10:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T10:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T10:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T11:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T11:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 49 in time block 2023-05-21T11:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T11:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T11:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T11:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T11:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T11:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T11:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 48 in time block 2023-05-21T11:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 100 in time block 2023-05-21T11:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T11:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T11:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T11:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T12:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T12:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 48 in time block 2023-05-21T12:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 98 in time block 2023-05-21T12:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T12:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T12:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T12:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T12:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T12:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 45 in time block 2023-05-21T12:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 94 in time block 2023-05-21T12:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T12:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T12:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T12:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T13:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T13:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 42 in time block 2023-05-21T13:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 90 in time block 2023-05-21T13:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T13:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T13:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T13:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T13:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T13:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 41 in time block 2023-05-21T13:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 88 in time block 2023-05-21T13:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T13:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T13:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T13:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T14:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T14:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 36 in time block 2023-05-21T14:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 84 in time block 2023-05-21T14:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T14:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T14:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T14:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T14:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T14:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 34 in time block 2023-05-21T14:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 81 in time block 2023-05-21T14:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T14:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T14:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T14:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T15:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 16 in time block 2023-05-21T15:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 33 in time block 2023-05-21T15:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 78 in time block 2023-05-21T15:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T15:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T15:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T15:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T15:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 15 in time block 2023-05-21T15:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 31 in time block 2023-05-21T15:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 77 in time block 2023-05-21T15:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T15:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T15:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T15:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T16:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 11 in time block 2023-05-21T16:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 29 in time block 2023-05-21T16:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 76 in time block 2023-05-21T16:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T16:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T16:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T16:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T16:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 11 in time block 2023-05-21T16:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 29 in time block 2023-05-21T16:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 76 in time block 2023-05-21T16:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T16:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T16:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T16:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T17:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 11 in time block 2023-05-21T17:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 29 in time block 2023-05-21T17:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 76 in time block 2023-05-21T17:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T17:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T17:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T17:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T17:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 10 in time block 2023-05-21T17:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 29 in time block 2023-05-21T17:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 75 in time block 2023-05-21T17:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T17:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T17:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T17:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T18:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 10 in time block 2023-05-21T18:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 29 in time block 2023-05-21T18:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 75 in time block 2023-05-21T18:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T18:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T18:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T18:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T18:30:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 10 in time block 2023-05-21T18:30:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 29 in time block 2023-05-21T18:30:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 73 in time block 2023-05-21T18:30:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T18:30:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T18:30:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T18:30:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T19:00:01Z\n",
      "200\n",
      "#soudalquickstep has tweets: 10 in time block 2023-05-21T19:00:01Z\n",
      "200\n",
      "(from:soudalquickstep) has tweets: 29 in time block 2023-05-21T19:00:01Z\n",
      "200\n",
      "200\n",
      "@ballero_94 has tweets: 72 in time block 2023-05-21T19:00:01Z\n",
      "200\n",
      "200\n",
      "@EvenepoelRemco has tweets: 100 in time block 2023-05-21T19:00:01Z\n",
      "200\n",
      "200\n",
      "@Pieter_Serry has tweets: 100 in time block 2023-05-21T19:00:01Z\n",
      "200\n",
      "@IlanWilder has tweets: 100 in time block 2023-05-21T19:00:01Z\n",
      "200\n",
      "200\n",
      "@soudalquickstep has tweets: 100 in time block 2023-05-21T19:30:01Z\n"
     ]
    }
   ],
   "source": [
    "# Auth\n",
    "bearer_token = \"XXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "# API endpoint\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "######\n",
    "######\n",
    "######\n",
    "###### loop through list of twitter\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "\n",
    "########## blocks to loop through. 6 blocks of 4 hours.\n",
    "#time_blocks = [\"T00:00:01Z\", \"T04:00:01Z\", \"T08:00:01Z\", \"T12:00:01Z\", \"T16:00:01Z\", \"T20:00:01Z\"]  #6 x 4 hours\n",
    "\n",
    "time_blocks_30min = [\"T00:00:01Z\", \"T00:30:01Z\", \"T01:00:01Z\", \"T01:30:01Z\", \"T02:00:01Z\", \"T02:30:01Z\", \"T03:00:01Z\", \"T03:30:01Z\",   # 4 hours 1\n",
    "                     \"T04:00:01Z\", \"T04:30:01Z\", \"T05:00:01Z\", \"T05:30:01Z\", \"T06:00:01Z\", \"T06:30:01Z\", \"T07:00:01Z\", \"T07:30:01Z\",   # 4 hours 2\n",
    "                     \"T08:00:01Z\", \"T08:30:01Z\", \"T09:00:01Z\", \"T09:30:01Z\", \"T10:00:01Z\", \"T10:30:01Z\", \"T11:00:01Z\", \"T11:30:01Z\",   # 4 hours 3\n",
    "                     \"T12:00:01Z\", \"T12:30:01Z\", \"T13:00:01Z\", \"T13:30:01Z\", \"T14:00:01Z\", \"T14:30:01Z\", \"T15:00:01Z\", \"T15:30:01Z\",   # 4 hours 4\n",
    "                     \"T16:00:01Z\", \"T16:30:01Z\", \"T17:00:01Z\", \"T17:30:01Z\", \"T18:00:01Z\", \"T18:30:01Z\", \"T19:00:01Z\", \"T19:30:01Z\",   # 4 hours 5\n",
    "                     \"T20:00:01Z\", \"T20:30:01Z\", \"T21:00:01Z\", \"T21:30:01Z\", \"T22:00:01Z\", \"T22:30:01Z\", \"T23:00:01Z\", \"T23:30:01Z\"    # 4 hours 6  \n",
    "                    ]  #30 min blocks\n",
    "\n",
    "#empty dataframe\n",
    "appended_data  = pd.DataFrame()\n",
    "\n",
    "for time in time_blocks_30min:\n",
    "    \n",
    "    #get the date (day/month) and time block as date\n",
    "    date = date_input + time\n",
    "\n",
    "    for account in list_of_twitter:\n",
    "        try:  \n",
    "            #query_params \n",
    "            query_params= {'query': account,\n",
    "                           'start_time': date,\n",
    "                            'place.fields':'contained_within,country,country_code,full_name,id,name,place_type',\n",
    "                            'tweet.fields': 'author_id,created_at,context_annotations', \n",
    "                           'user.fields':'username,location', \n",
    "                           'expansions':'author_id,in_reply_to_user_id,entities.mentions.username,referenced_tweets.id.author_id', \n",
    "                           'max_results':'100'}\n",
    "\n",
    "            #invoke response. Json response\n",
    "            json_response = connect_to_endpoint(search_url, query_params)\n",
    "\n",
    "            #see results. Push to a dataframe\n",
    "            input_tweets = json_normalize(json_response, 'data')\n",
    "\n",
    "            #clean tweets, add account columsn on the individual dataframe\n",
    "            input_tweets.insert(0, 'time_block', date)\n",
    "            input_tweets.insert(0, 'account', account)\n",
    "            print(account + \" has tweets: \" + str(input_tweets.shape[0]) + \" in time block \" + date)\n",
    "\n",
    "            #append dataframe to overall dataframe           \n",
    "            appended_data = pd.concat([appended_data, input_tweets], axis=0).reset_index(drop=True)\n",
    "        \n",
    "        except:  #when error in no tweets (data = empty) skip\n",
    "            pass\n",
    "            \n",
    "#clean text\n",
    "appended_data['text'] = appended_data['text'].str.replace(',|\\$|\\.|\\\\|\\â€¦|\\||\\!|\\-|\\'|\\?|\\:|\\#|\\@|\\n|\\_|\\(|\\)', '')\n",
    "\n",
    "#delete duplicate tweets\n",
    "df_input_tweets = appended_data.drop_duplicates(subset=[\"id\"], keep=\"first\")\n",
    "\n",
    "#add changed date/timestamp column\n",
    "df_input_tweets['timeStamp'] = pd.to_datetime(df_input_tweets['created_at'], format='%Y/%m/%d %H:%M:%S')\n",
    "df_input_tweets['timeStamp'] = df_input_tweets['timeStamp'].map(lambda x: str(x)[:-6])\n",
    "\n",
    "print(\"Number of total tweets in (with duplicates)\" + str(appended_data.shape[0]))\n",
    "print(\"Number of total tweets in (without duplicates)\" + str(df_input_tweets.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa953ff",
   "metadata": {},
   "source": [
    "# **5. Get user information**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295fcf31",
   "metadata": {},
   "source": [
    "### Get user information, like their user name\n",
    "- Users who made/produced the Tweet\n",
    "- If replied to a Tweet, who did the use reply to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e91224",
   "metadata": {},
   "source": [
    "## **5.1 User who Tweeted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebeb80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy tweets dataframe\n",
    "dataset_tweets = df_input_tweets\n",
    "\n",
    "#remove duplicates reply to to limit request\n",
    "dataset_tweets.drop_duplicates(subset=['author_id'], keep='first', inplace=True)\n",
    "\n",
    "# Auth\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAKNyJQEAAAAAqnvkEua0SASyd4UH%2FaY9oy09aDY%3D4UU34UOrNBUQyRzEPsKeYCkqv5FCAzIUOzycIVxnyY9FfHoGs4\"\n",
    "\n",
    "# API endpoint\n",
    "search_url = \"https://api.twitter.com/2/users/\"\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url):\n",
    "    response = requests.get(url, auth=bearer_oauth)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "####################\n",
    "\n",
    "list_users = []\n",
    "\n",
    "for x in dataset_tweets['author_id']:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        #get specific user information\n",
    "        url = search_url + x + \"?user.fields=public_metrics\"\n",
    "        json_response = connect_to_endpoint(url)\n",
    "\n",
    "        #normalize response\n",
    "        xs = list(json_response.values())\n",
    "        #dataset_user = json_normalize(json_response)\n",
    "        \n",
    "        author_id = xs[0][\"id\"]\n",
    "        user_name = xs[0][\"username\"]\n",
    "        name = xs[0][\"name\"]\n",
    "        followers_count = xs[0][\"public_metrics\"][\"followers_count\"]\n",
    "        following_count = xs[0][\"public_metrics\"][\"following_count\"]\n",
    "        tweet_count = xs[0][\"public_metrics\"][\"tweet_count\"]\n",
    "        listed_count = xs[0][\"public_metrics\"][\"listed_count\"]\n",
    "\n",
    "        #append response to list\n",
    "        list_users.append([author_id, user_name, name, followers_count, following_count, tweet_count, listed_count])\n",
    "        #list_users.append(dataset_user)\n",
    "    \n",
    "    except:  #when error in no tweets (data = empty) skip\n",
    "        pass\n",
    "    \n",
    "    \n",
    "#make new dataframe and append list\n",
    "dataset_tweets_app = dataset_tweets\n",
    "\n",
    "#list to df and append to existing df\n",
    "list_users_reshaped = np.array(list_users).reshape(-1,7)\n",
    "list_users_df = pd.DataFrame(list_users_reshaped, columns = ['author_id', 'username', 'name', 'followers_count', 'following_count', 'tweet_count', 'listed_count'])\n",
    "\n",
    "#join dataframes\n",
    "#dataset_tweets_and_user = pd.concat([dataset_tweets_app, list_users_df], axis=1, join=\"inner\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82806e7",
   "metadata": {},
   "source": [
    "## **5.2 In reply to user information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd29715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates reply to to limit request\n",
    "reply_to_inpt = df_input_tweets.drop_duplicates(subset=['in_reply_to_user_id'], keep='first')\n",
    "\n",
    "list_users_in_reply_to = []\n",
    "\n",
    "for x in reply_to_inpt['in_reply_to_user_id']:\n",
    "    try:\n",
    "        \n",
    "        if pd.isna(x) == False:\n",
    "\n",
    "            #get specific user information\n",
    "            url = search_url + str(x)\n",
    "            json_response = connect_to_endpoint(url)\n",
    "\n",
    "            #normalize response\n",
    "            dataset_user = json_normalize(json_response)\n",
    "\n",
    "            #append response to list\n",
    "            list_users_in_reply_to.append(dataset_user)\n",
    "                #print(list_users_in_reply_to) \n",
    "    \n",
    "        else:\n",
    "            print(\"No reply to someone\")\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#list to df and append to existing df\n",
    "list_users_reshaped_x = np.array(list_users_in_reply_to).reshape(-1,3)\n",
    "list_users_in_reply_to_df = pd.DataFrame(list_users_reshaped_x, columns = ['in_reply_to_user_id', 'name_reply_to', 'username_reply_to'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec654d",
   "metadata": {},
   "source": [
    "# **6. Change / Append columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop columns\n",
    "dataset_tweets_dropped = df_input_tweets.drop(['edit_history_tweet_ids', 'context_annotations', 'referenced_tweets'], axis=1)\n",
    "\n",
    "#add binary column. In reply to or retweet\n",
    "dataset_tweets_dropped['retweet_or_reply'] = [\"reply\" if pd.isna(x) == False else \"retweet\" for x in dataset_tweets_dropped['in_reply_to_user_id']]\n",
    "dataset_tweets_dropped[\"tweet_count\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de197a9",
   "metadata": {},
   "source": [
    "# **7. Sentiment Analysis - Using OCI AI Service - Language**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12184b3",
   "metadata": {},
   "source": [
    "## **7.1 Sentiment extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e990cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset to use in sentiment\n",
    "dataset = dataset_tweets_dropped\n",
    "\n",
    "# Initialize service client with default config file\n",
    "ai_language_client = oci.ai_language.AIServiceLanguageClient(config)\n",
    "\n",
    "#empty list\n",
    "results = []\n",
    "\n",
    "# Iterate over Pandas DF and apply Sentiment Detection to each row\n",
    "for index, row in dataset.iterrows():\n",
    "\n",
    "    textx = row[\"text\"]\n",
    "    keyx = row[\"id\"]\n",
    "\n",
    "    # ai call\n",
    "    batch_detect_language_sentiments_response = ai_language_client.batch_detect_language_sentiments(\n",
    "        batch_detect_language_sentiments_details=oci.ai_language.models.BatchDetectLanguageSentimentsDetails(\n",
    "            documents=[\n",
    "                oci.ai_language.models.TextDocument(\n",
    "                    key = keyx,\n",
    "                    text = textx,\n",
    "                    language_code=\"en\")],\n",
    "        ),    level=[\"SENTENCE\"])\n",
    "\n",
    "    # Extract Language Sentiments\n",
    "    formatted_response = batch_detect_language_sentiments_response.data.documents\n",
    "\n",
    "    rowid = formatted_response[0].key\n",
    "    sentenceSentiment = formatted_response[0].document_sentiment\n",
    "    positiveScore = formatted_response[0].document_scores[\"Positive\"]\n",
    "    neutralScore = formatted_response[0].document_scores[\"Neutral\"]\n",
    "    negativeScore = formatted_response[0].document_scores[\"Negative\"]\n",
    "    sentenceLength = formatted_response[0].sentences[0].length\n",
    "\n",
    "    # Append the extracted attributes to the results list\n",
    "    results.append([rowid, sentenceSentiment, positiveScore, neutralScore, negativeScore, sentenceLength])\n",
    "    \n",
    "    #print(results)\n",
    "\n",
    "# Convert list of lists to a pandas df\n",
    "resultsDF = pd.DataFrame(results, columns = ['id', 'Sentiment', 'PositiveScore', 'NeutralScore', 'NegativeScore', 'sentenceLength'])\n",
    "resultsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41a505",
   "metadata": {},
   "source": [
    "## **7.2 Append dataframe with sentiment per tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dfs\n",
    "df_out_1 = dataset_tweets_dropped.merge(resultsDF, how='left', on='id')\n",
    "\n",
    "#remove duplicates tweets. ID is unique\n",
    "df_out = df_out_1.drop_duplicates(subset=['id'], keep='first')\n",
    "\n",
    "#drop entities.mentions\n",
    "df_tweets_output = df_out.drop(['entities.mentions'], axis=1)\n",
    "\n",
    "print(\"Shape should be \" + str(df_input_tweets.shape))\n",
    "print(\"Output shape is \" + str(df_tweets_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4f13d",
   "metadata": {},
   "source": [
    "# **8. Extract entities from tweets and put in different table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2069f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_entities = []\n",
    "\n",
    "for index, row in df_input_tweets.iterrows():\n",
    "    \n",
    "    dummy = row['entities.mentions']\n",
    "    \n",
    "    try:\n",
    "        if len(dummy)==1:\n",
    "            username = dummy[0]['username']\n",
    "            username2 = np.nan\n",
    "            username3 = np.nan\n",
    "            results_list_entities.append([row['id'], username, username2, username3])\n",
    "        \n",
    "        elif len(dummy)==2:\n",
    "            username = dummy[0]['username']\n",
    "            username2 = dummy[1]['username']\n",
    "            username3 = np.nan\n",
    "            results_list_entities.append([row['id'], username, username2, username3])           \n",
    "            \n",
    "        else:\n",
    "            username = dummy[0]['username']\n",
    "            username2 = dummy[1]['username']\n",
    "            username3 = dummy[2]['username']\n",
    "\n",
    "            results_list_entities.append([row['id'], username, username2, username3])\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "mentions_df = pd.DataFrame(results_list_entities, columns=['id', 'metion_1', 'mention_2', 'mention_3'])\n",
    "mentions_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a21d37",
   "metadata": {},
   "source": [
    "# **9. Push results to database**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb319fd8",
   "metadata": {},
   "source": [
    "## **9.1 Connection to ADW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'ADWGIRO'\n",
    "database_user = 'XXXXX'\n",
    "database_password = 'XXXX'\n",
    "wallet_storage_directory = '/home/datascience/ADW/' \n",
    "\n",
    "# Create the wallet directory if missing: \n",
    "ads.set_documentation_mode(False)\n",
    "\n",
    "os.makedirs(wallet_storage_directory, mode=0o700, exist_ok=True)\n",
    "\n",
    "wallet_path = os.path.join(wallet_storage_directory, database_name)\n",
    "\n",
    "# Prepare to store ADB connection information\n",
    "adb_config = os.path.join(wallet_storage_directory, '.credentials')\n",
    "\n",
    "# Write a configuration file for login creds.\n",
    "config = configparser.ConfigParser()\n",
    "config.read(adb_config)\n",
    "config[database_name] = {'tns_admin': wallet_path,\n",
    "                         'sid': 'adwgiro_high',\n",
    "                         'user': database_user,\n",
    "                         'password': database_password}\n",
    "with open(adb_config, 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "\n",
    "# Read in the credentials configuration files\n",
    "my_config = configparser.ConfigParser()\n",
    "my_config.read(adb_config)\n",
    "\n",
    "# Limit the information to a specific database\n",
    "my_creds = my_config[database_name]\n",
    "\n",
    "# extract the wallet\n",
    "wallet_file = 'Wallet_{}.zip'.format(database_name)\n",
    "wallet_filename = os.path.join(wallet_storage_directory, wallet_file)\n",
    "if not os.path.exists(wallet_filename):\n",
    "    print(\"The file {} does not exist.\".format(wallet_filename))\n",
    "    print(\"Please copy the Wallet file, {}, into the directory {} then rerun this cell.\".format(wallet_file, wallet_filename))\n",
    "else:\n",
    "    os.makedirs(wallet_path, mode=0o700, exist_ok=True)\n",
    "    with ZipFile(wallet_filename, 'r') as zipObj:\n",
    "        zipObj.extractall(wallet_path)\n",
    "        \n",
    "        \n",
    "# Update the sqlnet.ora\n",
    "\n",
    "sqlnet_path = os.path.join(wallet_path, 'sqlnet.ora')\n",
    "sqlnet_original_path = os.path.join(wallet_path, 'sqlnet.ora.original')\n",
    "sqlnet_backup_path = os.path.join(wallet_path, 'sqlnet.ora.backup')\n",
    "if not os.path.exists(sqlnet_original_path):\n",
    "    shutil.copy(sqlnet_path, sqlnet_original_path)\n",
    "if os.path.exists(sqlnet_path):\n",
    "    shutil.copy(sqlnet_path, sqlnet_backup_path)\n",
    "sqlnet_re = re.compile('(WALLET_LOCATION\\s*=.*METHOD_DATA\\s*=.*DIRECTORY\\s*=\\s*\\\")(.*)(\\\".*)', \n",
    "                       re.IGNORECASE)\n",
    "tmp = NamedTemporaryFile()\n",
    "with open(sqlnet_path, 'rt') as sqlnet:\n",
    "    for line in sqlnet:\n",
    "        tmp.write(bytearray(sqlnet_re.subn(r'\\1{}\\3'.format(wallet_path), line)[0], \n",
    "                            encoding='utf-8'))\n",
    "tmp.flush()\n",
    "shutil.copy(tmp.name, sqlnet_path)\n",
    "tmp.close()\n",
    "\n",
    "# Add TNS_ADMIN to the environment\n",
    "os.environ['TNS_ADMIN'] = config[database_name].get('tns_admin')\n",
    "\n",
    "# Test the database connection\n",
    "creds = config[database_name]\n",
    "connect = 'sqlplus ' + creds.get('user') + '/' + creds.get('password') + '@' + creds.get('sid')\n",
    "print(os.popen(connect).read())\n",
    "\n",
    "#connection and engine\n",
    "uri = 'oracle+cx_oracle://' + creds['user'] + ':' + creds['password'] + '@' + creds['sid']\n",
    "os.environ['TNS_ADMIN'] = creds['tns_admin']\n",
    "engine = create_engine(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3c935",
   "metadata": {},
   "source": [
    "# **9.2 Reply Dataframe appending to database table**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0836ed",
   "metadata": {},
   "source": [
    "### **9.3.1. Query previous table to remove duplicates before appending new, unqiue rows to the same table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79348090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get entire table\n",
    "df_reply_to = pd.read_sql('SELECT * from GIRO.soudalquickstep_reply_to', con=engine)\n",
    "\n",
    "#join old and new tables\n",
    "df_reply_to_concat = pd.concat([list_users_in_reply_to_df, df_reply_to])\n",
    "\n",
    "# # #drop duplicates\n",
    "df_reply_to_concat_to_database = df_reply_to_concat.drop_duplicates(subset=['in_reply_to_user_id'], keep='first')\n",
    "\n",
    "#convert to string\n",
    "df_reply_to_concat_to_database['in_reply_to_user_id'] = df_reply_to_concat_to_database['in_reply_to_user_id'].astype('str') \n",
    "df_reply_to_concat_to_database['name_reply_to'] = df_reply_to_concat_to_database['name_reply_to'].astype('str') \n",
    "df_reply_to_concat_to_database['username_reply_to'] = df_reply_to_concat_to_database['username_reply_to'].astype('str') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b66cf3f",
   "metadata": {},
   "source": [
    "### **9.3.2. Push to database new entries (each time replaces the same table name with unique values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate table\n",
    "Conn = engine.connect()\n",
    "Conn.execute(\"TRUNCATE TABLE soudalquickstep_reply_to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff6ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_reply_to_concat_to_database.shape)\n",
    "\n",
    "#push results to database\n",
    "df_reply_to_concat_to_database.to_sql('soudalquickstep_reply_to', con=engine, index=False, if_exists=\"append\", dtype={\n",
    "            'in_reply_to_user_id': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'name_reply_to': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'username_reply_to': sqlalchemy.types.NVARCHAR(length=255) })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90599ce",
   "metadata": {},
   "source": [
    "# **9.3 Tweets_table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change column names\n",
    "df_tweets_output = df_tweets_output.rename(columns={'timeStamp': 'timestamp_x', 'Sentiment':'sentiment_x', 'PositiveScore':'positive_x', 'NeutralScore':'neutral_x', 'NegativeScore':'negative_x', 'sentenceLength':'sentence_length_x'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get entire table\n",
    "df_tweets_from_db = pd.read_sql('SELECT * from GIRO.soudalquickstep_tweets', con=engine)\n",
    "\n",
    "#join old and new tables\n",
    "df_tweets_concat = pd.concat([df_tweets_output, df_tweets_from_db])\n",
    "\n",
    "# # #drop duplicates\n",
    "df_tweets_concat_to_database = df_tweets_concat.drop_duplicates(subset=['id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ed7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate table\n",
    "Conn = engine.connect()\n",
    "Conn.execute(\"TRUNCATE TABLE soudalquickstep_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tweets_concat_to_database.shape)\n",
    "\n",
    "df_tweets_concat_to_database.to_sql('soudalquickstep_tweets', con=engine, index=False, if_exists=\"append\", dtype={\n",
    "            'account': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'time_block': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'created_at': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'text': sqlalchemy.types.NVARCHAR(length=500), \n",
    "            'in_reply_to_user_id': sqlalchemy.types.NVARCHAR(length=255),\n",
    "            'author_id': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'id': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'timestamp_x': sqlalchemy.types.NVARCHAR(length=255),  #sqlalchemy.DateTime()\n",
    "#             'data_name': sqlalchemy.types.NVARCHAR(length=255), \n",
    "#             'data_username': sqlalchemy.types.NVARCHAR(length=255),\n",
    "            'retweet_or_reply': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'tweet_count':  sqlalchemy.types.INTEGER(), \n",
    "            'sentiment_x': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'positive_x': sqlalchemy.types.Float(precision=3, asdecimal=True), \n",
    "            'neutral_x': sqlalchemy.types.Float(precision=3, asdecimal=True),\n",
    "            'negative_x': sqlalchemy.types.Float(precision=3, asdecimal=True), \n",
    "            'sentence_length_x':  sqlalchemy.types.INTEGER()     })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29e27a",
   "metadata": {},
   "source": [
    "# **9.4 Entities per tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ea3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mentions_df.to_csv(\"./df_entities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c75c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get entire table\n",
    "df_entities = pd.read_sql('SELECT * from GIRO.soudalquickstep_entities', con=engine)\n",
    "\n",
    "#join old and new tables\n",
    "df_entities_concat = pd.concat([mentions_df, df_entities])\n",
    "\n",
    "# # #drop duplicates\n",
    "df_entities_concat_to_datbase = df_entities_concat.drop_duplicates(subset=['id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ac9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate table\n",
    "Conn = engine.connect()\n",
    "Conn.execute(\"TRUNCATE TABLE soudalquickstep_entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b1ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_entities_concat_to_datbase.shape)\n",
    "\n",
    "#push results to database\n",
    "df_entities_concat_to_datbase.to_sql('soudalquickstep_entities', con=engine, index=False, if_exists=\"append\", dtype={\n",
    "            'id': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'mention_1': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'mention_2': sqlalchemy.types.NVARCHAR(length=255),\n",
    "            'mention_3': sqlalchemy.types.NVARCHAR(length=255)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18c5b8",
   "metadata": {},
   "source": [
    "# **9.5 Users data and nickname**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get entire table\n",
    "df_users = pd.read_sql('SELECT * from GIRO.soudalquickstep_users', con=engine)\n",
    "\n",
    "#change column names\n",
    "list_users_df = list_users_df.rename(columns={'followers_count': 'user_followers_count', 'following_count': 'user_following_count', 'tweet_count': 'user_tweet_count', 'listed_count': 'user_listed_count'})\n",
    "\n",
    "#join old and new tables\n",
    "df_users_concat = pd.concat([list_users_df, df_users])\n",
    "\n",
    "# # #drop duplicates\n",
    "df_users_concat_to_datbase = df_users_concat.drop_duplicates(subset=['author_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619559e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate table\n",
    "Conn = engine.connect()\n",
    "Conn.execute(\"TRUNCATE TABLE soudalquickstep_users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd841b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_users_concat_to_datbase.shape)\n",
    "\n",
    "#push results to database\n",
    "df_users_concat_to_datbase.to_sql('soudalquickstep_users', con=engine, index=False, if_exists=\"append\", dtype={\n",
    "            'author_id': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'username': sqlalchemy.types.NVARCHAR(length=255), \n",
    "            'name': sqlalchemy.types.NVARCHAR(length=255),\n",
    "            'followers_count':  sqlalchemy.types.INTEGER(),\n",
    "            'following_count':  sqlalchemy.types.INTEGER(),\n",
    "            'tweet_count':  sqlalchemy.types.INTEGER(),\n",
    "            'listed_count':  sqlalchemy.types.INTEGER()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e7740",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745ca38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6daca27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49a3c3a1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow28_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-tensorflow28_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
